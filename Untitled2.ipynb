{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a1f44e5-13f6-42b0-ba8e-23fd681f3e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üîç CHECKING WHICH COLUMNS NEED ENCODING\n",
      "======================================================================\n",
      "\n",
      "Your 18 columns:\n",
      "\n",
      " 1. default_profile                bool       (     2 unique) ‚úÖ Already numbers (True=1, False=0)\n",
      " 2. default_profile_image          bool       (     2 unique) ‚úÖ Already numbers (True=1, False=0)\n",
      " 3. description                    object     (29,124 unique) üìù TEXT - Needs encoding\n",
      " 4. favourites_count               float64    (10,000 unique) ‚úÖ Already numbers\n",
      " 5. followers_count                int64      ( 5,040 unique) ‚úÖ Already numbers\n",
      " 6. friends_count                  float64    ( 2,116 unique) ‚úÖ Already numbers\n",
      " 7. geo_enabled                    bool       (     2 unique) ‚úÖ Already numbers (True=1, False=0)\n",
      " 8. screen_name                    object     (37,373 unique) üìù TEXT - Needs encoding\n",
      " 9. statuses_count                 int64      (14,775 unique) ‚úÖ Already numbers\n",
      "10. verified                       bool       (     2 unique) ‚úÖ Already numbers (True=1, False=0)\n",
      "11. average_tweets_per_day         float64    (32,159 unique) ‚úÖ Already numbers\n",
      "12. account_age_days               int64      ( 4,158 unique) ‚úÖ Already numbers\n",
      "13. account_type                   object     (     2 unique) üìù TEXT - Needs encoding\n",
      "14. follower_friend_ratio          float64    (20,691 unique) ‚úÖ Already numbers\n",
      "15. tweets_per_follower            float64    (30,438 unique) ‚úÖ Already numbers\n",
      "16. profile_completeness           float64    (     5 unique) ‚úÖ Already numbers\n",
      "17. description_has_url            int64      (     2 unique) ‚úÖ Already numbers\n",
      "18. name_has_numbers               int64      (     2 unique) ‚úÖ Already numbers\n",
      "\n",
      "======================================================================\n",
      "SUMMARY\n",
      "======================================================================\n",
      "\n",
      "üìù Columns that need encoding: 3\n",
      "   ‚Ä¢ description\n",
      "   ‚Ä¢ screen_name\n",
      "   ‚Ä¢ account_type\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your data\n",
    "df = pd.read_csv('twitter_bot_final_features.csv')\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üîç CHECKING WHICH COLUMNS NEED ENCODING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nYour 18 columns:\\n\")\n",
    "\n",
    "for i, col in enumerate(df.columns, 1):\n",
    "    dtype = df[col].dtype\n",
    "    unique = df[col].nunique()\n",
    "    \n",
    "    if dtype == 'object':  # Text columns\n",
    "        status = \"üìù TEXT - Needs encoding\"\n",
    "    elif dtype == 'bool':  # Boolean (True/False)\n",
    "        status = \"‚úÖ Already numbers (True=1, False=0)\"\n",
    "    else:  # Numbers\n",
    "        status = \"‚úÖ Already numbers\"\n",
    "    \n",
    "    print(f\"{i:2d}. {col:30s} {str(dtype):10s} ({unique:>6,} unique) {status}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "text_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "print(f\"\\nüìù Columns that need encoding: {len(text_cols)}\")\n",
    "for col in text_cols:\n",
    "    print(f\"   ‚Ä¢ {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8355954-126b-40d3-ae24-8c5b4c399778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 1: Encoding Target Variable 'account_type'\n",
      "======================================================================\n",
      "\n",
      "Before encoding:\n",
      "account_type\n",
      "human    25005\n",
      "bot      12420\n",
      "Name: count, dtype: int64\n",
      "\n",
      "After encoding:\n",
      "  account_type  account_type_encoded\n",
      "0          bot                     0\n",
      "1        human                     1\n",
      "\n",
      "Value counts:\n",
      "account_type_encoded\n",
      "1    25005\n",
      "0    12420\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('twitter_bot_final_features.csv')\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# STEP 1: ENCODE TARGET VARIABLE (account_type)\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 1: Encoding Target Variable 'account_type'\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Show before\n",
    "print(f\"\\nBefore encoding:\")\n",
    "print(df['account_type'].value_counts())\n",
    "\n",
    "# Encode: bot=0, human=1\n",
    "label_encoder = LabelEncoder()\n",
    "df['account_type_encoded'] = label_encoder.fit_transform(df['account_type'])\n",
    "\n",
    "# Show after\n",
    "print(f\"\\nAfter encoding:\")\n",
    "print(df[['account_type', 'account_type_encoded']].drop_duplicates().sort_values('account_type'))\n",
    "\n",
    "print(f\"\\nValue counts:\")\n",
    "print(df['account_type_encoded'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8ef73b9-9a9d-4db0-9c46-03260e2c2e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 2: Dropping Text Columns\n",
      "======================================================================\n",
      "\n",
      "Reason: We already extracted features from these columns:\n",
      "  ‚Ä¢ description ‚Üí has_description, description_has_url\n",
      "  ‚Ä¢ screen_name ‚Üí name_has_numbers\n",
      "\n",
      "Dropping 3 columns:\n",
      "  ‚ùå description          (29,124 unique values)\n",
      "  ‚ùå screen_name          (37,373 unique values)\n",
      "  ‚ùå account_type         (     2 unique values)\n",
      "\n",
      "‚úì Dropped text columns\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# STEP 2: DROP TEXT COLUMNS (features already extracted)\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 2: Dropping Text Columns\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nReason: We already extracted features from these columns:\")\n",
    "print(\"  ‚Ä¢ description ‚Üí has_description, description_has_url\")\n",
    "print(\"  ‚Ä¢ screen_name ‚Üí name_has_numbers\")\n",
    "\n",
    "columns_to_drop = ['description', 'screen_name', 'account_type']\n",
    "\n",
    "print(f\"\\nDropping {len(columns_to_drop)} columns:\")\n",
    "for col in columns_to_drop:\n",
    "    unique = df[col].nunique()\n",
    "    print(f\"  ‚ùå {col:20s} ({unique:>6,} unique values)\")\n",
    "\n",
    "df_encoded = df.drop(columns=columns_to_drop)\n",
    "\n",
    "print(f\"\\n‚úì Dropped text columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c68024c-e8fd-4f01-b0f1-45b6f17eea79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 3: Converting Boolean Columns to Integers\n",
      "======================================================================\n",
      "\n",
      "Found 4 boolean columns:\n",
      "  ‚Ä¢ default_profile\n",
      "  ‚Ä¢ default_profile_image\n",
      "  ‚Ä¢ geo_enabled\n",
      "  ‚Ä¢ verified\n",
      "\n",
      "‚úì Converted: True ‚Üí 1, False ‚Üí 0\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# STEP 3: CONVERT BOOLEAN TO INTEGER (0/1)\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 3: Converting Boolean Columns to Integers\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "bool_cols = df_encoded.select_dtypes(include=['bool']).columns.tolist()\n",
    "\n",
    "print(f\"\\nFound {len(bool_cols)} boolean columns:\")\n",
    "for col in bool_cols:\n",
    "    print(f\"  ‚Ä¢ {col}\")\n",
    "\n",
    "# Convert True/False to 1/0\n",
    "for col in bool_cols:\n",
    "    df_encoded[col] = df_encoded[col].astype(int)\n",
    "\n",
    "print(f\"\\n‚úì Converted: True ‚Üí 1, False ‚Üí 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cabbd0b-e74b-4305-b75e-9623020a0fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 4: FINAL VERIFICATION\n",
      "======================================================================\n",
      "\n",
      "Final shape: (37425, 16)\n",
      "\n",
      "All columns and their types:\n",
      "\n",
      " 1. default_profile                int64      (     2 unique) ‚úÖ Numeric\n",
      " 2. default_profile_image          int64      (     2 unique) ‚úÖ Numeric\n",
      " 3. favourites_count               float64    (10,000 unique) ‚úÖ Numeric\n",
      " 4. followers_count                int64      ( 5,040 unique) ‚úÖ Numeric\n",
      " 5. friends_count                  float64    ( 2,116 unique) ‚úÖ Numeric\n",
      " 6. geo_enabled                    int64      (     2 unique) ‚úÖ Numeric\n",
      " 7. statuses_count                 int64      (14,775 unique) ‚úÖ Numeric\n",
      " 8. verified                       int64      (     2 unique) ‚úÖ Numeric\n",
      " 9. average_tweets_per_day         float64    (32,159 unique) ‚úÖ Numeric\n",
      "10. account_age_days               int64      ( 4,158 unique) ‚úÖ Numeric\n",
      "11. follower_friend_ratio          float64    (20,691 unique) ‚úÖ Numeric\n",
      "12. tweets_per_follower            float64    (30,438 unique) ‚úÖ Numeric\n",
      "13. profile_completeness           float64    (     5 unique) ‚úÖ Numeric\n",
      "14. description_has_url            int64      (     2 unique) ‚úÖ Numeric\n",
      "15. name_has_numbers               int64      (     2 unique) ‚úÖ Numeric\n",
      "16. account_type_encoded           int64      (     2 unique) ‚úÖ Numeric\n",
      "\n",
      "======================================================================\n",
      "VERIFICATION SUMMARY\n",
      "======================================================================\n",
      "‚úÖ Numeric columns: 16/16\n",
      "‚ùå Non-numeric columns: 0\n",
      "\n",
      "üéâ ALL COLUMNS ARE NUMERIC - READY FOR MACHINE LEARNING!\n",
      "\n",
      "Missing values: 0\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# STEP 4: VERIFY ALL COLUMNS ARE NUMERIC\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 4: FINAL VERIFICATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nFinal shape: {df_encoded.shape}\")\n",
    "print(f\"\\nAll columns and their types:\\n\")\n",
    "\n",
    "numeric_count = 0\n",
    "non_numeric = []\n",
    "\n",
    "for i, col in enumerate(df_encoded.columns, 1):\n",
    "    dtype = df_encoded[col].dtype\n",
    "    unique = df_encoded[col].nunique()\n",
    "    \n",
    "    if dtype in ['int64', 'int32', 'float64', 'float32']:\n",
    "        status = \"‚úÖ Numeric\"\n",
    "        numeric_count += 1\n",
    "    else:\n",
    "        status = \"‚ùå NOT NUMERIC!\"\n",
    "        non_numeric.append(col)\n",
    "    \n",
    "    print(f\"{i:2d}. {col:30s} {str(dtype):10s} ({unique:>6,} unique) {status}\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*70)\n",
    "print(\"VERIFICATION SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"‚úÖ Numeric columns: {numeric_count}/{len(df_encoded.columns)}\")\n",
    "print(f\"‚ùå Non-numeric columns: {len(non_numeric)}\")\n",
    "\n",
    "if len(non_numeric) == 0:\n",
    "    print(\"\\nüéâ ALL COLUMNS ARE NUMERIC - READY FOR MACHINE LEARNING!\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è Warning: {len(non_numeric)} columns still need encoding:\")\n",
    "    for col in non_numeric:\n",
    "        print(f\"   ‚Ä¢ {col}\")\n",
    "\n",
    "# Check for missing values\n",
    "missing = df_encoded.isnull().sum().sum()\n",
    "print(f\"\\nMissing values: {missing}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8c45b8b-11d8-4d81-b33e-4f5a8588c50a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 5: SAVING ENCODED DATASET\n",
      "======================================================================\n",
      "\n",
      "‚úÖ Saved to: twitter_bot_encoded.csv\n",
      "‚úÖ Rows: 37,425\n",
      "‚úÖ Columns: 16\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# STEP 5: SAVE ENCODED DATASET\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 5: SAVING ENCODED DATASET\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "output_file = 'twitter_bot_encoded.csv'\n",
    "df_encoded.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"\\n‚úÖ Saved to: {output_file}\")\n",
    "print(f\"‚úÖ Rows: {len(df_encoded):,}\")\n",
    "print(f\"‚úÖ Columns: {len(df_encoded.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd88d8b2-72f4-4413-a384-7fb5b825a8db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 6: PREPARING FOR MODELING\n",
      "======================================================================\n",
      "\n",
      "üéØ TARGET VARIABLE (what we predict):\n",
      "   ‚Ä¢ account_type_encoded\n",
      "     ‚Üí 0 = bot (12,420 samples)\n",
      "     ‚Üí 1 = human (25,005 samples)\n",
      "\n",
      "üìä FEATURE COLUMNS (what we use to predict): 15\n",
      "    1. default_profile\n",
      "    2. default_profile_image\n",
      "    3. favourites_count\n",
      "    4. followers_count\n",
      "    5. friends_count\n",
      "    6. geo_enabled\n",
      "    7. statuses_count\n",
      "    8. verified\n",
      "    9. average_tweets_per_day\n",
      "   10. account_age_days\n",
      "   11. follower_friend_ratio\n",
      "   12. tweets_per_follower\n",
      "   13. profile_completeness\n",
      "   14. description_has_url\n",
      "   15. name_has_numbers\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# STEP 6: CREATE FEATURE/TARGET SPLIT PREVIEW\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 6: PREPARING FOR MODELING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Identify target and features\n",
    "target_col = 'account_type_encoded'\n",
    "feature_cols = [col for col in df_encoded.columns if col != target_col]\n",
    "\n",
    "print(f\"\\nüéØ TARGET VARIABLE (what we predict):\")\n",
    "print(f\"   ‚Ä¢ {target_col}\")\n",
    "print(f\"     ‚Üí 0 = bot ({(df_encoded[target_col]==0).sum():,} samples)\")\n",
    "print(f\"     ‚Üí 1 = human ({(df_encoded[target_col]==1).sum():,} samples)\")\n",
    "\n",
    "print(f\"\\nüìä FEATURE COLUMNS (what we use to predict): {len(feature_cols)}\")\n",
    "for i, col in enumerate(feature_cols, 1):\n",
    "    print(f\"   {i:2d}. {col}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbe9bd57-9c65-4992-9aa8-c082d4e803e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "STEP 1: Loading encoded data...\n",
      "âœ“ Data loaded\n",
      "  Shape: (37425, 16)\n",
      "  Rows: 37,425\n",
      "  Columns: 16\n",
      "\n",
      "======================================================================\n",
      "STEP 2: Separating Features and Target\n",
      "======================================================================\n",
      "\n",
      "ðŸŽ¯ Target variable (y):\n",
      "  Column: account_type_encoded\n",
      "  Shape: (37425,)\n",
      "  Values: 0 (bot), 1 (human)\n",
      "\n",
      "ðŸ“Š Features (X):\n",
      "  Shape: (37425, 15)\n",
      "  Number of features: 15\n",
      "\n",
      "  Feature columns:\n",
      "     1. default_profile\n",
      "     2. default_profile_image\n",
      "     3. favourites_count\n",
      "     4. followers_count\n",
      "     5. friends_count\n",
      "     6. geo_enabled\n",
      "     7. statuses_count\n",
      "     8. verified\n",
      "     9. average_tweets_per_day\n",
      "    10. account_age_days\n",
      "    11. follower_friend_ratio\n",
      "    12. tweets_per_follower\n",
      "    13. profile_completeness\n",
      "    14. description_has_url\n",
      "    15. name_has_numbers\n",
      "\n",
      "======================================================================\n",
      "STEP 3: Checking Class Distribution\n",
      "======================================================================\n",
      "\n",
      "Original dataset distribution:\n",
      "account_type_encoded\n",
      "0    12420\n",
      "1    25005\n",
      "Name: count, dtype: int64\n",
      "\n",
      "  Bot (0):   12,420 (33.19%)\n",
      "  Human (1): 25,005 (66.81%)\n",
      "  Ratio:     2.01:1 (Human:Bot)\n",
      "\n",
      "======================================================================\n",
      "STEP 4: Splitting Data (80% Train, 20% Test)\n",
      "======================================================================\n",
      "\n",
      "âœ“ Split complete\n",
      "\n",
      "ðŸ“Š Training Set:\n",
      "  Features (X_train): (29940, 15)\n",
      "  Target (y_train):   (29940,)\n",
      "  Total samples:      29,940 (80%)\n",
      "\n",
      "ðŸ“Š Test Set:\n",
      "  Features (X_test):  (7485, 15)\n",
      "  Target (y_test):    (7485,)\n",
      "  Total samples:      7,485 (20%)\n",
      "\n",
      "======================================================================\n",
      "STEP 5: Verifying Stratification\n",
      "======================================================================\n",
      "\n",
      "Training set distribution:\n",
      "  Bot (0):    9,936 (33.19%)\n",
      "  Human (1): 20,004 (66.81%)\n",
      "\n",
      "Test set distribution:\n",
      "  Bot (0):    2,484 (33.19%)\n",
      "  Human (1):  5,001 (66.81%)\n",
      "\n",
      "âœ“ Class ratios are preserved in both sets!\n",
      "\n",
      "======================================================================\n",
      "STEP 6: Saving Split Datasets\n",
      "======================================================================\n",
      "âœ“ Saved: train_data.csv (29,940 rows)\n",
      "âœ“ Saved: test_data.csv (7,485 rows)\n",
      "\n",
      "======================================================================\n",
      "âœ… TRAIN-TEST SPLIT COMPLETE!\n",
      "======================================================================\n",
      "\n",
      "Summary:\n",
      "  â€¢ Original data:     37,425 samples\n",
      "  â€¢ Training set:      29,940 samples (80%)\n",
      "  â€¢ Test set:           7,485 samples (20%)\n",
      "  â€¢ Features:              15 columns\n",
      "  â€¢ Stratification:    âœ“ Class ratios preserved\n",
      "\n",
      "Files created:\n",
      "  âœ“ train_data.csv - For training models\n",
      "  âœ“ test_data.csv  - For evaluating models\n",
      "\n",
      "Variables in memory:\n",
      "  â€¢ X_train - Training features\n",
      "  â€¢ X_test  - Test features\n",
      "  â€¢ y_train - Training labels\n",
      "  â€¢ y_test  - Test labels\n",
      "\n",
      "ðŸš€ READY FOR MODEL TRAINING!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# STEP 1: LOAD ENCODED DATA\n",
    "# ============================================================\n",
    "print(\"\\nSTEP 1: Loading encoded data...\")\n",
    "\n",
    "df = pd.read_csv('twitter_bot_encoded.csv')\n",
    "\n",
    "print(f\"âœ“ Data loaded\")\n",
    "print(f\"  Shape: {df.shape}\")\n",
    "print(f\"  Rows: {len(df):,}\")\n",
    "print(f\"  Columns: {len(df.columns)}\")\n",
    "\n",
    "# ============================================================\n",
    "# STEP 2: SEPARATE FEATURES (X) AND TARGET (y)\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 2: Separating Features and Target\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Target variable (what we want to predict)\n",
    "target_column = 'account_type_encoded'\n",
    "y = df[target_column]\n",
    "\n",
    "# Features (everything except target)\n",
    "X = df.drop(columns=[target_column])\n",
    "\n",
    "print(f\"\\nðŸŽ¯ Target variable (y):\")\n",
    "print(f\"  Column: {target_column}\")\n",
    "print(f\"  Shape: {y.shape}\")\n",
    "print(f\"  Values: 0 (bot), 1 (human)\")\n",
    "\n",
    "print(f\"\\nðŸ“Š Features (X):\")\n",
    "print(f\"  Shape: {X.shape}\")\n",
    "print(f\"  Number of features: {X.shape[1]}\")\n",
    "\n",
    "print(f\"\\n  Feature columns:\")\n",
    "for i, col in enumerate(X.columns, 1):\n",
    "    print(f\"    {i:2d}. {col}\")\n",
    "\n",
    "# ============================================================\n",
    "# STEP 3: CHECK CLASS DISTRIBUTION\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 3: Checking Class Distribution\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nOriginal dataset distribution:\")\n",
    "print(y.value_counts().sort_index())\n",
    "\n",
    "bot_count = (y == 0).sum()\n",
    "human_count = (y == 1).sum()\n",
    "bot_percent = (bot_count / len(y)) * 100\n",
    "human_percent = (human_count / len(y)) * 100\n",
    "\n",
    "print(f\"\\n  Bot (0):   {bot_count:>6,} ({bot_percent:>5.2f}%)\")\n",
    "print(f\"  Human (1): {human_count:>6,} ({human_percent:>5.2f}%)\")\n",
    "print(f\"  Ratio:     {human_count/bot_count:.2f}:1 (Human:Bot)\")\n",
    "\n",
    "# ============================================================\n",
    "# STEP 4: PERFORM TRAIN-TEST SPLIT\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 4: Splitting Data (80% Train, 20% Test)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Split: 80% training, 20% testing\n",
    "# stratify=y ensures same bot/human ratio in both sets\n",
    "# random_state=42 makes results reproducible\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, \n",
    "    y, \n",
    "    test_size=0.20,      # 20% for testing\n",
    "    random_state=42,     # for reproducibility\n",
    "    stratify=y           # keep same class ratio\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ“ Split complete\")\n",
    "print(f\"\\nðŸ“Š Training Set:\")\n",
    "print(f\"  Features (X_train): {X_train.shape}\")\n",
    "print(f\"  Target (y_train):   {y_train.shape}\")\n",
    "print(f\"  Total samples:      {len(X_train):,} (80%)\")\n",
    "\n",
    "print(f\"\\nðŸ“Š Test Set:\")\n",
    "print(f\"  Features (X_test):  {X_test.shape}\")\n",
    "print(f\"  Target (y_test):    {y_test.shape}\")\n",
    "print(f\"  Total samples:      {len(X_test):,} (20%)\")\n",
    "\n",
    "# ============================================================\n",
    "# STEP 5: VERIFY STRATIFICATION (same ratio in train/test)\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 5: Verifying Stratification\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nTraining set distribution:\")\n",
    "train_bot = (y_train == 0).sum()\n",
    "train_human = (y_train == 1).sum()\n",
    "print(f\"  Bot (0):   {train_bot:>6,} ({train_bot/len(y_train)*100:>5.2f}%)\")\n",
    "print(f\"  Human (1): {train_human:>6,} ({train_human/len(y_train)*100:>5.2f}%)\")\n",
    "\n",
    "print(f\"\\nTest set distribution:\")\n",
    "test_bot = (y_test == 0).sum()\n",
    "test_human = (y_test == 1).sum()\n",
    "print(f\"  Bot (0):   {test_bot:>6,} ({test_bot/len(y_test)*100:>5.2f}%)\")\n",
    "print(f\"  Human (1): {test_human:>6,} ({test_human/len(y_test)*100:>5.2f}%)\")\n",
    "\n",
    "print(f\"\\nâœ“ Class ratios are preserved in both sets!\")\n",
    "\n",
    "# ============================================================\n",
    "# STEP 6: SAVE SPLIT DATA (OPTIONAL)\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 6: Saving Split Datasets\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Save train set\n",
    "train_df = X_train.copy()\n",
    "train_df['account_type_encoded'] = y_train\n",
    "train_df.to_csv('train_data.csv', index=False)\n",
    "print(f\"âœ“ Saved: train_data.csv ({len(train_df):,} rows)\")\n",
    "\n",
    "# Save test set\n",
    "test_df = X_test.copy()\n",
    "test_df['account_type_encoded'] = y_test\n",
    "test_df.to_csv('test_data.csv', index=False)\n",
    "print(f\"âœ“ Saved: test_data.csv ({len(test_df):,} rows)\")\n",
    "\n",
    "# ============================================================\n",
    "# FINAL SUMMARY\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"âœ… TRAIN-TEST SPLIT COMPLETE!\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nSummary:\")\n",
    "print(f\"  â€¢ Original data:     {len(df):>6,} samples\")\n",
    "print(f\"  â€¢ Training set:      {len(X_train):>6,} samples (80%)\")\n",
    "print(f\"  â€¢ Test set:          {len(X_test):>6,} samples (20%)\")\n",
    "print(f\"  â€¢ Features:          {X_train.shape[1]:>6,} columns\")\n",
    "print(f\"  â€¢ Stratification:    âœ“ Class ratios preserved\")\n",
    "\n",
    "print(\"\\nFiles created:\")\n",
    "print(\"  âœ“ train_data.csv - For training models\")\n",
    "print(\"  âœ“ test_data.csv  - For evaluating models\")\n",
    "\n",
    "print(\"\\nVariables in memory:\")\n",
    "print(\"  â€¢ X_train - Training features\")\n",
    "print(\"  â€¢ X_test  - Test features\")\n",
    "print(\"  â€¢ y_train - Training labels\")\n",
    "print(\"  â€¢ y_test  - Test labels\")\n",
    "\n",
    "print(\"\\nðŸš€ READY FOR MODEL TRAINING!\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
